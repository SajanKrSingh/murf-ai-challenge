# üß† Day 08: Integrating a Large Language Model (LLM)

Welcome to Day 8 of the **#30DaysOfVoiceAgents** challenge! Today marks a significant milestone as we give our voice agent a "brain" by integrating a powerful Large Language Model.

This update introduces a new backend endpoint that connects to **Google's Gemini API**. This allows our application to process text queries and generate intelligent, human-like responses, transforming it from a simple bot into a true intelligent assistant.



---

## ‚ú® Key Features

-   **LLM Integration:** The application is now connected to Google's Gemini API, enabling advanced natural language understanding and generation.
-   **New Backend Endpoint (`/llm/query`):** A dedicated FastAPI endpoint that accepts a text query, sends it to the Gemini model, and returns the generated response.
-   **Intelligent Responses:** The agent can now answer questions, explain concepts, and engage in more complex interactions.
-   **Secure API Key Management:** The new `GEMINI_API_KEY` is securely managed alongside our other keys in the `.env` file.

---

## üõ†Ô∏è Tech Stack

-   **Backend:** Python, FastAPI, Uvicorn
-   **LLM Service:** **Google Gemini**
-   **Transcription Service:** AssemblyAI
-   **Text-to-Speech Service:** Murf AI
-   **API Communication:** `requests`, `google-generativeai`
-   **Environment Management:** `python-dotenv`
-   **Frontend:** HTML5, CSS3, JavaScript

---

## üöÄ Getting Started

Follow these steps to set up and run the project with its new LLM capabilities.

### 1. Prerequisites

-   Python 3.8+ installed
-   A Murf AI account and API key
-   An AssemblyAI account and API key
-   A **Google Gemini API key**

### 2. Get Your Gemini API Key

1.  Visit the [Google AI for Developers quickstart page](https://ai.google.dev/gemini-api/docs/quickstart).
2.  Click on **"Get API key in Google AI Studio"** and follow the steps to create a new, free API key.
3.  Copy the generated key.

### 3. Clone the Repository

```bash
git clone [https://github.com/SajanKrSingh/30-days-of-voice-agents.git](https://github.com/SajanKrSingh/30-days-of-voice-agents.git)
cd 30-days-of-voice-agents/day-08
```

### 4. Create a Virtual Environment

```bash
python -m venv venv
# On Windows:
.\venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate
```

### 5. Install Dependencies

Install all required libraries, including the new `google-generativeai` package.

```bash
pip install -r requirements.txt
```

### 6. Set Up Environment Variables

Create or update the `.env` file in the `day-08/` directory. It must now contain all three API keys.

```env
MURF_API_KEY="your_murf_ai_api_key_here"
ASSEMBLYAI_API_KEY="your_assemblyai_api_key_here"
GEMINI_API_KEY="your_google_gemini_api_key_here"
```

---

## ‚ñ∂Ô∏è Run the Application

Start the FastAPI server using Uvicorn.

```bash
uvicorn app:app --reload
```

---

## üß™ How to Test the New Endpoint

Since there are no UI changes for this task, you will test the new endpoint using FastAPI's automatic documentation.

1.  Open your browser and navigate to `http://127.0.0.1:8000/docs`.
2.  Find and expand the new **POST `/llm/query`** endpoint.
3.  Click the **"Try it out"** button.
4.  In the `text` field, enter a question (e.g., "Explain the theory of relativity in two sentences").
5.  Click the **"Execute"** button.
6.  Scroll down to the **Responses** section to see the answer generated by the Gemini model.
